{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython\n",
    "from __future__ import generators, print_function, unicode_literals\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "    :param str dep_model: Stanford dependencie mode\n",
      "    :param str stp_dir: path of stanford parser jar\n",
      "    :param str raise_e: raise exception if stanford-parser.jar is not found\n",
      "    \"\"\"\n",
      " \n",
      "    def __init__(self, str senna_dir=\"\", str stp_dir=\"\", str dep_model='edu.stanford.nlp.trees.EnglishGrammaticalStructure',bool raise_e=False):\n",
      "                                                                                                                           ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/home/codingmart/.cache/ipython/cython/_cython_magic_1a5edcf63d13ef3fe611183fb7b76dfa.pyx:31:124: 'bool' is not a type identifier\n",
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "        print(\"default values:\\nsenna path:\\n\", self.senna_path, \\\n",
      "             \"\\nDependencie parser:\\n\", self.dep_par_path)\n",
      "        print(\"Stanford parser clr\", \" \".join(self.default_jar_cli))\n",
      "        print(\"**\"*50)\n",
      "\n",
      "    def check_stp_jar(self, str path, bool raise_e=False ):\n",
      "                                     ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/home/codingmart/.cache/ipython/cython/_cython_magic_1a5edcf63d13ef3fe611183fb7b76dfa.pyx:74:38: 'bool' is not a type identifier\n"
     ]
    }
   ],
   "source": [
    "%%cython \n",
    "#!user/jawahar/anaconda/bin/python\n",
    "import os\n",
    "from platform import architecture, system\n",
    "\n",
    "import subprocess\n",
    "class Annotator:\n",
    "    \"\"\"\n",
    "    A general interface of the SENNA/Stanford Dependency Extractor pipeline that supports any of\n",
    "    the operations specified in SUPPORTED_OPERATIONS.\n",
    "    SUPPORTED_OPERATIONS: It provides\n",
    "    Part of Speech Tags, Semantic Role Labels, Shallow Parsing (Chunking),\n",
    "    Named Entity Recognisation (NER), Dependency Parse and\n",
    "    Syntactic Constituency Parse.\n",
    "    Applying multiple operations at once has the speed advantage. For example,\n",
    "    senna v3.0 will calculate the POS tags in case you are extracting the named\n",
    "    entities. Applying both of the operations will cost only the time of\n",
    "    extracting the named entities. Same is true for dependency Parsing.\n",
    "    SENNA pipeline has a fixed maximum size of the sentences that it can read.\n",
    "    By default it is 1024 token/sentence. If you have larger sentences, changing\n",
    "    the MAX_SENTENCE_SIZE value in SENNA_main.c should be considered and your\n",
    "    system specific binary should be rebuilt. Otherwise this could introduce\n",
    "    misalignment errors\n",
    "    and for Dependency Parser the requirement is Java Runtime Environment :)\n",
    "\n",
    "    :param str senna_dur: path where is located\n",
    "    :param str dep_model: Stanford dependencie mode\n",
    "    :param str stp_dir: path of stanford parser jar\n",
    "    :param str raise_e: raise exception if stanford-parser.jar is not found\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, str senna_dir=\"\", str stp_dir=\"\", str dep_model='edu.stanford.nlp.trees.EnglishGrammaticalStructure',bool raise_e=False):\n",
    "        \"\"\"\n",
    "        init function of Annotator class\n",
    "        \"\"\"\n",
    "        self.senna_path = \"\"\n",
    "        self.dep_par_path = \"\"\n",
    "\n",
    "        if not senna_dir:\n",
    "            if 'SENNA' in os.environ:\n",
    "                self.senna_path = os.path.normpath(os.environ['SENNA']) + os.path.sep\n",
    "                exe_file_2 = self.get_senna_bin(self.senna_path)\n",
    "                if not os.path.isfile(exe_file_2):\n",
    "                    raise OSError(\"Senna executable expected at %s or %s but not found\" % (senna_dir,exe_file_2))\n",
    "        else:\n",
    "            self.senna_path = senna_dir.strip().rstrip(os.path.sep)+os.path.sep\n",
    "\n",
    "        if not stp_dir:\n",
    "            import pntl.tools \n",
    "            self.dep_par_path = pntl.tools.__file__.rsplit(os.path.sep, 1)[0]+os.path.sep\n",
    "            self.check_stp_jar(self.dep_par_path, raise_e=True)\n",
    "        else:\n",
    "            self.dep_par_path = stp_dir+ os.path.sep\n",
    "            self.check_stp_jar(self.dep_par_path, raise_e)\n",
    "        \n",
    "        self.dep_par_model = dep_model\n",
    "\n",
    "        self.default_jar_cli = ['java', '-cp', 'stanford-parser.jar',\\\n",
    "                        self.dep_par_model, \\\n",
    "                      '-treeFile', 'in.parse', '-collapsed']\n",
    "        self.print_values()\n",
    "\n",
    "\n",
    "    def print_values(self):\n",
    "        \"\"\"\n",
    "        displays the current set of values such as SENNA location, stanford parser jar,\n",
    "        jar command interface\n",
    "        \"\"\"\n",
    "        print(\"**\"*50)\n",
    "        print(\"default values:\\nsenna path:\\n\", self.senna_path, \\\n",
    "             \"\\nDependencie parser:\\n\", self.dep_par_path)\n",
    "        print(\"Stanford parser clr\", \" \".join(self.default_jar_cli))\n",
    "        print(\"**\"*50)\n",
    "\n",
    "    def check_stp_jar(self, str path, bool raise_e=False ):\n",
    "        \"\"\"\n",
    "        Check the stanford parser is present in the given directions\n",
    "        and nested searching will be added in futurwork\n",
    "\n",
    "        :param str path: path of where the stanford parser is present\n",
    "        :param bool raise_e: to raise exception with user wise and default `False`\n",
    "              don't raises exception\n",
    "        :return: given path if it is valid one or return boolean `False` or\n",
    "             if raise FileNotFoundError on raise_exp=True\n",
    "        :rtype: bool\n",
    "\n",
    "        \"\"\"\n",
    "        gpath = path\n",
    "        path = os.listdir(path)\n",
    "        file_found = False\n",
    "        for file in path:\n",
    "            if file.endswith(\".jar\"):\n",
    "                if file.startswith(\"stanford-parser\"):\n",
    "                    file_found = True\n",
    "        if not file_found and raise_e:\n",
    "            raise FileNotFoundError(\"`stanford-parser.jar` is not found in the path `%s`\\n \\\n",
    "              to handle the issue follow this link \\\n",
    "                   [https://github.com/jawahar273/practNLPTools-lite/blob/master/doc/ \\\n",
    "                    stanford_installing_issues.md]\"%(gpath))\n",
    "        return file_found\n",
    "\n",
    "    @property\n",
    "    def stp_dir(self):\n",
    "        \"\"\"The return the path of stanford parser jar location\n",
    "        and set the path for Dependency Parse at run time(this is python @property)\n",
    "        \"\"\"\n",
    "        return self.dep_par_path\n",
    "\n",
    "    @stp_dir.setter\n",
    "    def stp_dir(self, val):\n",
    "        if os.path.isdir(val):\n",
    "            self.dep_par_path = val+os.path.sep\n",
    "\n",
    "\n",
    "    @property\n",
    "    def senna_dir(self):\n",
    "        \"\"\"The return the path of senna location\n",
    "        and set the path for senna at run time(this is python @property)\n",
    "\n",
    "        :rtype: string\n",
    "        \"\"\"\n",
    "        return self.senna_path\n",
    "\n",
    "    @senna_dir.setter\n",
    "    def senna_dir(self, val):\n",
    "        if os.path.isdir(val):\n",
    "            self.senna_path = val+os.path.sep\n",
    "\n",
    "\n",
    "    @property\n",
    "    def jar_cli(self):\n",
    "        \"\"\"\n",
    "        The return cli for standford-parser.jar(this is python @property)\n",
    "\n",
    "        :rtype: string\n",
    "        \"\"\"\n",
    "        return \" \".join(self.default_jar_cli)\n",
    "\n",
    "    @jar_cli.setter\n",
    "    def jar_cli(self, val):\n",
    "        self.default_jar_cli = val.split()\n",
    "\n",
    "    def get_senna_bin(self, os_name):\n",
    "        \"\"\"\n",
    "        get the current os executable binary file.\n",
    "\n",
    "        :param str os_name: os name like Linux, Darwin, Windows\n",
    "        :return: the corresponding exceutable object file of senna\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "\n",
    "        if os_name == 'Linux':\n",
    "            bits = architecture()[0]\n",
    "            if bits == '64bit':\n",
    "                executable = 'senna-linux64'\n",
    "            elif bits == '32bit':\n",
    "                executable = 'senna-linux32'\n",
    "            else:\n",
    "                executable = 'senna'\n",
    "        elif os_name == 'Darwin':\n",
    "            executable = 'senna-osx'\n",
    "        elif os_name == 'Windows':\n",
    "            executable = 'senna-win32.exe'\n",
    "        return self.senna_path+executable\n",
    "\n",
    "    def get_senna_tag_batch(self, sentences):\n",
    "        \"\"\"\n",
    "        Communicates with senna through lower level communiction(sub process)\n",
    "        and converted the console output(default is file writing).\n",
    "        On batch processing each end is add with new line.\n",
    "\n",
    "        :param list sentences: list of sentences for batch processes\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        input_data = \"\"\n",
    "        for sentence in sentences:\n",
    "            input_data += sentence+\"\\n\"\n",
    "        input_data = input_data[:-1]\n",
    "        package_directory = os.path.dirname(self.senna_path)\n",
    "        os_name = system()\n",
    "        executable = self.get_senna_bin(os_name)\n",
    "        senna_executable = os.path.join(package_directory, executable)\n",
    "        cwd = os.getcwd()\n",
    "        os.chdir(package_directory)\n",
    "        pipe = subprocess.Popen(senna_executable, stdout=subprocess.PIPE, stdin=subprocess.PIPE)\n",
    "        senna_stdout = pipe.communicate(input=input_data.encode('utf-8'))[0]\n",
    "        os.chdir(cwd)\n",
    "        return senna_stdout.decode().split(\"\\n\\n\")[0:-1]\n",
    "\n",
    "    @classmethod\n",
    "    def help_conll_format(cls):\n",
    "        \"\"\"\n",
    "         With the help of this method, detail of senna \n",
    "         arguments are displayed\n",
    "        \"\"\"\n",
    "        return cls.get_conll_format.__doc__.split(\"\\n\\n\")[1]\n",
    "\n",
    "    def get_conll_format(self, sentence, options='-srl -pos -ner -chk -psg'):\n",
    "        \"\"\"\n",
    "        Communicates with senna through lower level communiction(sub process)\n",
    "          and converted the console output(default is file writing)\n",
    "           with CoNLL format and options to pass\n",
    "\n",
    "        -verbose\n",
    "          \tDisplay model informations (on the standard error output,\n",
    "               so it does not mess up the tag outputs).\n",
    "        -notokentags\n",
    "          \tDo not output tokens (first output column).\n",
    "        -offsettags\n",
    "        \tOutput start/end character offset (in the sentence), for each token.\n",
    "        -iobtags\n",
    "          \tOutput IOB tags instead of IOBES.\n",
    "        -brackettags\n",
    "          \tOutput 'bracket' tags instead of IOBES.\n",
    "        -path <path>\n",
    "          \tSpecify the path to the SENNA data/ and hash/ directories,\n",
    "               if you do not run SENNA in its original directory.\n",
    "                The path must end by \"/\".\n",
    "\t-usrtokens\n",
    "  \t  \tUse user's tokens (space separated) instead of SENNA tokenizer.\n",
    " \t-posvbs\n",
    "\t \tUse verbs outputed by the POS tagger instead of SRL style verbs for SRL task.\n",
    "          You might want to use this, as the SRL training task ignore some verbs\n",
    "            (many \"be\" and \"have\") which might be not what you want.\n",
    " \t-usrvbs <file>\n",
    " \t\tUse user's verbs (given in <file>) instead of SENNA verbs for SRL task.\n",
    "          The file must contain one line per token, with an empty line between each sentence.\n",
    "            A line which is not a \"-\" corresponds to a verb.\n",
    "\t-pos\n",
    "\t-chk\n",
    "\t-ner\n",
    "\t-srl\n",
    "\t-psg\n",
    "\t      Instead of outputing tags for all tasks, SENNA will output tags for the specified\n",
    "              (one or more) tasks.\n",
    "\n",
    "        :param str or list: list of sentences for batch processes\n",
    "        :param list: list of arguments\n",
    "        :return: senna tagged output\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        if isinstance(options, str):\n",
    "            options = options.strip().split()\n",
    "\n",
    "        input_data = sentence\n",
    "        package_directory = os.path.dirname(self.senna_path)\n",
    "        #print(\"testing dir\",self.dep_par_path, package_directory)\n",
    "        os_name = system()\n",
    "        executable = self.get_senna_bin(os_name)\n",
    "        senna_executable = os.path.join(package_directory, executable)\n",
    "        cwd = os.getcwd()\n",
    "        os.chdir(package_directory)\n",
    "        args = [senna_executable]\n",
    "        args.extend(options)\n",
    "        pipe = subprocess.Popen(args, stdout=subprocess.PIPE, stdin=subprocess.PIPE)\n",
    "        senna_stdout = pipe.communicate(input=\" \".join(input_data).encode('utf-8'))[0]\n",
    "        os.chdir(cwd)\n",
    "        return senna_stdout.decode(\"utf-8\").strip()\n",
    "\n",
    "    def get_senna_tag(self, sentence):\n",
    "        \"\"\"\n",
    "        Communicates with senna through lower level communiction(sub process)\n",
    "        and converted the console output(default is file writing)\n",
    "\n",
    "        :param str or listsentences: list of sentences for batch processes\n",
    "        :return: senna tagged output\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        input_data = sentence\n",
    "        package_directory = os.path.dirname(self.senna_path)\n",
    "        #print(\"testing dir\",self.dep_par_path, package_directory)\n",
    "        os_name = system()\n",
    "        executable = self.get_senna_bin(os_name)\n",
    "        senna_executable = os.path.join(package_directory, executable)\n",
    "        cwd = os.getcwd()\n",
    "        os.chdir(package_directory)\n",
    "        pipe = subprocess.Popen(senna_executable, stdout=subprocess.PIPE, stdin=subprocess.PIPE)\n",
    "        senna_stdout = pipe.communicate(input=\" \".join(input_data).encode('utf-8'))[0]\n",
    "        os.chdir(cwd)\n",
    "        return senna_stdout\n",
    "\n",
    "    def get_dependency(self, parse):\n",
    "        \"\"\"\n",
    "        Change to the Stanford parser direction and process the works\n",
    "\n",
    "        :param str parse: parse is the input(tree format) and it is writen in as file\n",
    "\n",
    "        :return: stanford dependency universal format\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        #print(\"\\nrunning.........\")\n",
    "        package_directory = os.path.dirname(self.dep_par_path)\n",
    "        cwd = os.getcwd()\n",
    "        os.chdir(package_directory)\n",
    "        \n",
    "        with open(self.senna_path+os.path.sep+\"in.parse\", \"w\", encoding='utf-8') as parsefile:\n",
    "            parsefile.write(parse)\n",
    "        pipe = subprocess.Popen(self.default_jar_cli, stdout=subprocess.PIPE, \\\n",
    "             stderr=subprocess.PIPE)\n",
    "        pipe.wait()\n",
    "        stanford_out = pipe.stdout.read()\n",
    "        os.chdir(cwd)\n",
    "        return stanford_out.decode(\"utf-8\").strip()\n",
    "\n",
    "    def get_batch_annotations(self, sentences, dep_parse=True):\n",
    "        \"\"\"\n",
    "        :param list sentences: list of sentences\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        annotations = []\n",
    "        batch_senna_tags = self.get_senna_tag_batch(sentences)\n",
    "        for senna_tags in batch_senna_tags:\n",
    "            annotations += [self.get_annoations(senna_tags=senna_tags)]\n",
    "        if dep_parse:\n",
    "            syntax_tree = \"\"\n",
    "            for annotation in annotations:\n",
    "                syntax_tree += annotation['syntax_tree']\n",
    "            dependencies = self.get_dependency(syntax_tree).split(\"\\n\\n\")\n",
    "            #print dependencies\n",
    "            if len(annotations) == len(dependencies):\n",
    "                for dependencie, annotation in zip(dependencies, annotations):\n",
    "                    annotation[\"dep_parse\"] = dependencie\n",
    "        return annotations\n",
    "\n",
    "\n",
    "    def get_annoations(self, sentence=\"\", senna_tags=None, dep_parse=True):\n",
    "        \"\"\"\n",
    "        passing the string to senna and performing aboue given nlp process\n",
    "        and the returning them in a form of `dict()`\n",
    "\n",
    "        :param str or list sentence: a sentence or list of sentence for nlp process.\n",
    "        :param str or list senna_tags:  this values are by SENNA processed string\n",
    "        :param bool  batch: the change the mode into batch processing process\n",
    "        :param bool dep_parse: to tell the code and user need to communicate with stanford parser\n",
    "        :return: the dict() of every out in the process such as ner, dep_parse, srl, verbs etc.\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        annotations = {}\n",
    "        if not senna_tags:\n",
    "            senna_tags = self.get_senna_tag(sentence).decode()\n",
    "            senna_tags = [x.strip() for x in senna_tags.split(\"\\n\")];senna_tags = senna_tags[0:-2]\n",
    "        else:\n",
    "            senna_tags = [x.strip() for x in senna_tags.split(\"\\n\")]\n",
    "        no_verbs = len(senna_tags[0].split(\"\\t\"))-6\n",
    "\n",
    "        words = []\n",
    "        pos = []\n",
    "        chunk = []\n",
    "        ner = []\n",
    "        verb = []\n",
    "        srls = []\n",
    "        syn = []\n",
    "        for senna_tag in senna_tags:\n",
    "            senna_tag = senna_tag.split(\"\\t\")\n",
    "            words += [senna_tag[0].strip()]\n",
    "            pos += [senna_tag[1].strip()]\n",
    "            chunk += [senna_tag[2].strip()]\n",
    "            ner += [senna_tag[3].strip()]\n",
    "            verb += [senna_tag[4].strip()]\n",
    "            srl = []\n",
    "            for i in range(5, 5+no_verbs):\n",
    "                srl += [senna_tag[i].strip()]\n",
    "            srls += [tuple(srl)]\n",
    "            syn += [senna_tag[-1]]\n",
    "        roles = []\n",
    "        for j in range(no_verbs):\n",
    "            role = {}\n",
    "            i = 0\n",
    "            temp = \"\"\n",
    "            curr_labels = [x[j] for x in srls]\n",
    "            for curr_label in curr_labels:\n",
    "                splits = curr_label.split(\"-\")\n",
    "                if splits[0] == \"S\":\n",
    "                    if len(splits) == 2:\n",
    "                        if splits[1] == \"V\":\n",
    "                            role[splits[1]] = words[i]\n",
    "                        else:\n",
    "                            if splits[1] in role:\n",
    "                                role[splits[1]] += \" \"+words[i]\n",
    "                            else:\n",
    "                                role[splits[1]] = words[i]\n",
    "                    elif len(splits) == 3:\n",
    "                        if splits[1]+\"-\"+splits[2] in role:\n",
    "                            role[splits[1]+\"-\"+splits[2]] += \" \"+words[i]\n",
    "                        else:\n",
    "                            role[splits[1]+\"-\"+splits[2]] = words[i]\n",
    "                elif splits[0] == \"B\":\n",
    "                    temp = temp+\" \"+words[i]\n",
    "                elif splits[0] == \"I\":\n",
    "                    temp = temp+\" \"+words[i]\n",
    "                elif splits[0] == \"E\":\n",
    "                    temp = temp+\" \"+words[i]\n",
    "                    if len(splits) == 2:\n",
    "                        if splits[1] == \"V\":\n",
    "                            role[splits[1]] = temp.strip()\n",
    "                        else:\n",
    "                            if splits[1] in role:\n",
    "                                role[splits[1]] += \" \"+temp\n",
    "                                role[splits[1]] = role[splits[1]].strip()\n",
    "                            else:\n",
    "                                role[splits[1]] = temp.strip()\n",
    "                    elif len(splits) == 3:\n",
    "                        if splits[1]+\"-\"+splits[2] in role:\n",
    "                            role[splits[1]+\"-\"+splits[2]] += \" \"+temp\n",
    "                            role[splits[1]+\"-\"+splits[2]] = role[splits[1]+\"-\"+splits[2]].strip()\n",
    "                        else:\n",
    "                            role[splits[1]+\"-\"+splits[2]] = temp.strip()\n",
    "                    temp = \"\"\n",
    "                i += 1\n",
    "            if \"V\" in role:\n",
    "                roles += [role]\n",
    "        annotations['words'] = words\n",
    "        annotations['pos'] = list(zip(words, pos))\n",
    "        annotations['ner'] = list(zip(words, ner))\n",
    "        annotations['srl'] = roles\n",
    "        annotations['verbs'] = [x for x in verb if x != \"-\"]\n",
    "        annotations['chunk'] = list(zip(words, chunk))\n",
    "        annotations['dep_parse'] = \"\"\n",
    "        annotations['syntax_tree'] = \"\"\n",
    "        for (word_, syn_, pos_) in zip(words, syn, pos):\n",
    "            annotations['syntax_tree'] += syn_.replace(\"*\", \"(\"+pos_+\" \"+word_+\")\")\n",
    "        #annotations['syntax_tree']=annotations['syntax_tree'].replace(\"S1\",\"S\")\n",
    "        if dep_parse:\n",
    "            annotations['dep_parse'] = self.get_dependency(annotations['syntax_tree'])\n",
    "        return annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
